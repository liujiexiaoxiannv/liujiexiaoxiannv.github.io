<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[mysql笔记]]></title>
    <url>%2F2019%2F10%2F17%2Fmysql%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[一 常用命令 先连接mysql终端 A服务器连接B服务器的mysql mysql -h rm-m5e9u8q5la8y35m8y.mysql.rds.aliyuncs.com -u ebeasy_psro_r -p ebsy_pro_db 1.desc eb_jinli_report_one; 查看表结构 2.show create table users\G; 建表语句 3.DROP TABLE table_name ; 删除表 4.truncate table table_name 清空表 5.source /home/xiaoayong/aa.sql 执行sql文件,文件位于A服务器 在A服务器root用户下 ##带条件导出数据 mysqldump --column-statistics=0 -h rm-m5e9u8q5la8y35m8y.mysql.rds.aliyuncs.com -u ebeasy_psro_r -p ebstat_pro_db ebsy_pro_db --where=&quot;type=1 and value=0&quot; &gt; /home/xiaoayong/eb_gionee_report_zero2.sql 在输入密码 导出到A服务器 /home/xiaoayong目录下 6.更新 UPDATE eb_jinli_report_one SET zsykq_lv = ROUND((zsykqdj_uv/dbtabdj_uv)*100,2), xqyssfh_pv = 1884739, xqyssfh_uv=105950 where type=0 and date_url=20190905; 7.创建视图 CREATE VIEW `订单数据` AS SELECT id `id`, d `日期`, c `订单数`, CASE p WHEN 2 THEN &apos;blibli&apos; WHEN 3 THEN &apos;tokopiedia&apos; WHEN 4 THEN &apos;bukalapak&apos; WHEN 5 THEN &apos;lazada&apos; ELSE &apos;all&apos; END AS `平台名称`, g `订单金额(gmv)`, r `总佣金`, r `预计返现`, u `订单用户数`, s `客单价`, a `人均下单率` FROM eb_report_order ORDER BY stat_date DESC,id DESC;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3学习笔记]]></title>
    <url>%2F2019%2F10%2F12%2Fpython3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[一：测试环境 cmd 输入python 即可开始学习教程 1：深入 Python 流程控制 1) if … elif … elif else 2) Python 的 for 语句依据任意序列（链表或字符串）中的子项，按它们在序列中的顺序来进行迭代 3) 如果你需要一个数值序列，内置函数 range() 会很方便，它生成一个等差级数链表: 4) break 和 continue 语句, 以及循环中的 else 子句 5) pass 语句 函数 关键字 def 引入了一个函数 定义。在其后必须跟有函数名和包括形式参数的圆括号。函数体语句从下一行开始，必须是缩进的。 函数体的第一行语句可以是可选的字符串文本，这个字符串是函数的文档字符串，或者称为 docstring。 在 Python 中，你也可以定义包含若干参数的函数。这里有三种可用的形式，也可以混合使用。 4.7.1. 默认参数值 4.7.2. 关键字参数 4.7.3. 可变参数列表 4.7.4. 参数列表的分拆 4.7.5. Lambda 形式]]></content>
      <categories>
        <category>python3</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[metabase使用笔记]]></title>
    <url>%2F2019%2F09%2F06%2Fmetabase%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[一 安装 https://github.com/metabase/metabase 安装完填好数据库后 二 使用 可以先创建视图 ROP VIEW v_jinli_three_taobao; CREATE VIEW v_jinli_three_taobao AS SELECT stat_date, tcxs_pv, jhdj_pv FROM eb_jinli_report_three WHERE type=1; DROP VIEW `v_jinli_three_pinduoduo`; CREATE VIEW `v_jinli_three_pinduoduo` AS SELECT stat_date, tcxs_pv, jhdj_pv FROM eb_jinli_report_three WHERE type=2; DROP VIEW `v_jinli_four_all`; CREATE VIEW `v_jinli_four_all` AS SELECT stat_date, bgqd_pv, tcxs_pv, tcjh_pv, dbtabzs_pv, dbtabdj_pv, fwgwzsy_pv, zsykqdj_pv FROM eb_jinli_report_four WHERE type=0; DROP VIEW `金立输出PV表`; CREATE VIEW `金立输出PV表` AS SELECT f.stat_date `日期`, bgqd_pv `帮购app打开PV`, f.tcxs_pv `帮购首页助手弹窗弹出PV`, tcjh_pv `帮购首页助手弹窗点击PV`, dbtabzs_pv `帮购底部助手tab展示PV`, dbtabdj_pv `帮购底部助手tab点击PV`, t.tcxs_pv `淘宝首页助手弹窗弹出PV`, t.jhdj_pv `淘宝首页助手弹窗点击PV`, p.tcxs_pv `拼多多首页助手弹窗弹出PV`, p.jhdj_pv `拼多多首页助手弹窗点击PV`, fwgwzsy_pv `访问助手开启页PV`, zsykqdj_pv `助手开关开启点击PV` FROM v_jinli_four_all AS f, v_jinli_three_taobao as t, v_jinli_three_pinduoduo as p WHERE f.stat_date = t.stat_date AND f.stat_date = p.stat_date ORDER BY f.stat_date; 在终端执行这些命令 然后登陆浏览器metabase admin重新打开窗口同步数据 即可看到刚才创建的视图 save你想要的视图 save到你想放在分类下]]></content>
      <categories>
        <category>sql db</category>
      </categories>
      <tags>
        <tag>metabase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang笔记]]></title>
    <url>%2F2019%2F08%2F13%2Fgolang%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[常用知识点一 部署 windows下取别的名字 SET CGO_ENABLED=0 //这个不需要 SET GOOS=windows go build -o proxy-win-amd64.exe main.go start /b proxy-win-amd64.exe linux下取别的名字 SET CGO_ENABLED=0 //这个不需要 SET GOOS=linux go build -o proxy-linux-amd64 main.go nohup proxy-linux-amd64 server --mode=dev &amp; nohup proxy-linux-amd64 &amp; 二 debug goland 点击 debug go build main.go 查看console输出 查看debugger窗口输出 具体错误信息 三 golang 整形转字符串 strconv.Itoa(a) golang字符串分割成数组遍历 itemidString := &quot;sss,aaa,bb&quot; chrstr := strings.Split(itemidString, &quot;,&quot;) if len(chrstr) != 0 { for _, va := range chrstr { //va就是sss } } 字符串转float64 strconv.ParseFloat(value.Pay_price, 64) 四 golang调试 fmt.Printf(“v1 type:%T\n”, value.Discount) //打印变量类型 beego.Info(&quot;sssssaaa&quot;,value.Discount) //记录日志]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop/spark笔记]]></title>
    <url>%2F2019%2F08%2F13%2Fhadoop-spark%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[这里是centos6.8上安装单机版spark 一. 安装JDK 二. 安装spark。 tar -zxvf spark-2.3.1-bin-hadoop2.7.tgz mv spark-2.3.1-bin-hadoop2.7 spark-2.3.1 vim /etc/profile export SPARK_HOME=/opt/spark-2.3.1 export PATH=$PATH:$SPARK_HOME/bin source /etc/profile cd /opt/spark-2.3.1/conf/ cp spark-env.sh.template spark-env.sh vim spark-env.sh export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.181-3.b13.el7_5.x86_64 #这里是你jdk的安装路径 export SPARK_HOME=/opt/spark-2.3.1 export SPARK_MASTER_IP=XXX.XX.XX.XXX #将这里的xxx改为自己的Linux的ip地址 source spark-env.sh cd /opt/spark-2.3.1/conf/ cp slaves.template slaves vim slaves 在文件的最后加上如下配置： localhost source slaves cd sbin/ ./start-all.sh ./start-master.sh ./start-slave.sh spark://node1:7077 或者 pyspark sparkShell 三 centos环境部署python脚本 统计日志并写入xls 安装xlwt 一 安装pip curl -O https://bootstrap.pypa.io/get-pip.py python get-pip.py 二 安装xlrd--读 xlwt--写 xlrd：是python从excel读数据的第三方控件； xlwt：是python从excel写数据的第三方控件； xlutils：是python使用xlrd、xlwt的工具箱。若安装不成功，可能原因是需要安装setuptools。 pip install xlrd pip install xlwt pip install xlutils 基于日志算每个字段的值 cat * | grep &apos;EVENT_GOODS_DETAIL_PV&apos; | wc -l cat ${log_path} | grep -E &apos; &quot;nm&quot;:&quot;SQG_TAOBAO_SEARCH_ACCURATE_RESULT_CLICK&quot; | &quot;nm&quot;:&quot;SQG_TAOBAO_SEARCH_SIMILAR_RESULT_CLICK&quot; &apos; | wc -l //专区入口点击人数 根据m1去重 第三列3,3 cat * | grep &apos;&quot;nm&quot;:&quot;JINGANG_CLICK_EVERYTIME&quot;&apos; | grep &apos;&quot;name&quot;:&quot;大额神券&quot;&apos; | uniq | sort -t &apos;,&apos; -k 3,3 -u | wc -l //打印符合条件的m1，在第四列 cat -n * | grep &apos; &quot;nm&quot;:&quot;USER_START_APK&quot; &apos; | awk -F: &apos;{print $4}&apos; //也可以用jq cat * | jq &apos;. | {nm:.JINGANG_CLICK_EVERYTIME,name:.淘宝白菜}&apos; | wc -l 具体脚本代码----python 注意python for循环缩进 #!/usr/bin/env python # coding=utf-8 from pyspark import SparkContext from xlwt import * #import xlwt file=Workbook(encoding = &apos;utf-8&apos;) #指定file以utf-8的格式打开 table=file.add_sheet(&apos;baobiaoone&apos;) sc=SparkContext(appName=&quot;jinlifour&quot;) # sc.setLogLevel(&quot;ERROR&quot;) sc.setLogLevel(&quot;INFO&quot;) rdd=sc.textFile(&quot;file:///home/xiaoayong/work/jinli_qingdianshang/20190818&quot;) # rdd = sc.textFile(&apos;../csv/csv1/*&apos;) #print(rdd.count()) numAs=rdd.filter(lambda s:&apos;&quot;nm&quot;:&quot;GIONEE_OPEN_BANGO&quot;&apos; in s).count() numAsa=rdd.filter(lambda s:&apos;&quot;nm&quot;:&quot;GIONEE_BANGO_HELPER_DIALOG_SHOW&quot;&apos; in s).count() numAsb=rdd.filter(lambda s:&apos;&quot;nm&quot;:&quot;GIONEE_BANGO_HELPER_DIALOG_ACTIVATE_CLICK&quot;&apos; in s).count() numAsc=rdd.filter(lambda s:&apos;&quot;nm&quot;:&quot;GIONEE_BANGO_HELPER_DIALOG_COUSTOM_BACKGROUND&quot;&apos; in s).count() data={&quot;1&quot;:[&quot;张三&quot;,numAs,numAsa,100],&quot;2&quot;:[&quot;李四&quot;,numAsb,numAsc,95],&quot;3&quot;:[&quot;王五&quot;,60,66,68]} title = [&quot;学号&quot;,&quot;姓名&quot;,&quot;语文成绩&quot;,&quot;数学成绩&quot;,&quot;英语成绩&quot;,&quot;总分&quot;,&quot;平均分&quot;] for i in range(len(title)): # 循环列 table.write(0,i,title[i]) # 将title数组中的字段写入到0行i列中 for line in data: # 循环字典 print(&apos;line:&apos;,line) table.write(int(line),0,line) # 将line写入到第int(line)行，第0列中 summ = data[line][2] + data[line][3] # 成绩总分 table.write(int(line),5,summ) # 总分 table.write(int(line),6,summ/3) # 平均分 for i in range(len(data[line])): table.write(int(line),i+1,data[line][i]) file.save(&apos;baobiaoone.xls&apos;) //窗口统计 pyspark textFile=sc.textFile(&quot;hdfs://nameservice1/songshu/track/zheng_shihui/20190813/&quot;) textFile.count() spark.read.format(&quot;json&quot;).load(&quot;file:///home/xiaoayong/work/jinli_qingdianshang/20190818&quot;).createOrReplaceTempView(&quot;ds&quot;) spark.read.format(&quot;json&quot;).load(&quot;hdfs://nameservice1/songshu/track/jinli_qingdianshang/` date -d &apos;yesterday&apos; +&apos;%Y%m%d&apos; ` &quot;).createOrReplaceTempView(&quot;ds&quot;) spark.sql(&quot;SELECT * FROM ds&quot;).show() spark.sql(&quot;SELECT * FROM ds where nm=&apos;GIONEE_OPEN_BANGO&apos; &quot;).count() rdd = sc.textFile(&quot;file:///home/xiaoayong/work/jinli_qingdianshang/20190818&quot;) numAs=rdd.filter(lambda s:&apos;GIONEE_OPEN_BANGO&apos; in s).count() print(numAs) //crontab 10 01 * * * bash /home/xiaoayong/work/script/everyday.sh 1&gt;/home/xiaoayong/work/script/everyday.log 2&gt;&amp;1 25 02 * * * bash /home/xiaoayong/work/script/jinlireportone.sh 1&gt;/home/xiaoayong/work/script/jinlione.log 2&gt;&amp;1 0 14 * * * user/bin/python /home/xiaoayong/work/script/gethdfslog.py 1&gt;/home/xiaoayong/work/script/everyday.log 2&gt;&amp;1 0 14 * * * /opt/spark-2.1.0/bin/spark-submit bbb.py 1&gt;/home/xiaoayong/work/script/everyday.log 2&gt;&amp;1 链接网址 https://blog.csdn.net/yzh_1346983557/article/details/81624708 //单机版部署安装 http://spark.apache.org/ //官网 http://spark.apache.org/docs/latest/sql-programming-guide.html //学习sql http://spark.apache.org/docs/latest/quick-start.html //这个好像是入门的 https://www.cnblogs.com/xyf9575/p/7448613.html 第二次在 15号机重装 15 号docker安装pyspark 已经安装了 java jdk 和 python2.7.5 cd /data/server/pineddwget http://mirror.bit.edu.cn/apache/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgzwget https://downloads.lightbend.com/scala/2.13.0/scala-2.13.0.tgz tar zxvf spark-2.4.3-bin-hadoop2.7.tgzmv spark-2.4.3-bin-hadoop2.7 spark-2.4.3tar zxvf scala-2.13.0.tgzvim /etc/profile 加入export SPARK_HOME=/data/server/pinedd/spark-2.4.3export PATH=$SPARK_HOME/bin:$PATHexport PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.7-src.zip:$PYTHONPATH source /etc/profilepyspark 安装EPEL源：yum install epel-release 安装完EPEL源后，可以查看下jq包是否存在：yum list jq 安装jq：yum install jq yum install -y sendemail //shell 安装邮箱发送curl -O https://bootstrap.pypa.io/get-pip.py //安装pippython get-pip.py //很慢 二 安装xlrd–读 xlwt–写xlrd：是python从excel读数据的第三方控件；xlwt：是python从excel写数据的第三方控件；xlutils：是python使用xlrd、xlwt的工具箱。若安装不成功，可能原因是需要安装setuptools。pip install xlrdpip install xlwtpip install xlutils cp spark-env.sh.template spark-env.sh #export SCALA_HOME=/opt/scala-2.13.0export JAVA_HOME=/data/program/jdkexport SPARK_HOME=/data/server/pinedd/spark-2.4.3export SPARK_MASTER_IP=1.1.1.39 #export SPARK_EXECUTOR_MEMORY=512Mexport SPARK_WORKER_MEMORY=2Gexport SPARK_MASTER_PORT=7077 vim /etc/hosts1.1.1.39 pinedd-001 cp slaves.template slavesvim slaves在文件的最后加上如下配置：localhost 三 windows7使用Intellij IDEA编辑器运行pyspark 1) new project 选择Python 2) 在Project SDK中 NEW...选择运行环境 Add Python Interpreter（增加python 编译） 这四个都是可以跑的 1 Virtualenv Environment Python的虚拟环境可以使一个Python程序拥有独立的库library和解释器interpreter，而不用与其他Python程序共享统一个library和interpreter。虚拟环境的好处是避免了不同Python程序间的互相影响.例如程序A需要某个库的1.0版本，而程序B需要同样这个库的2.0版本，如果程序B执行则A就不能执行了。见formatlog里的venv 2 Conda Environment 3 System Interpreter system interpreter表示本地的解释器 4 Pipenv Environment pip 是 Python 最常用的包管理器，该工具提供了对Python 包的查找、下载、安装、卸载的功能。它能自动处理依赖 如果说venv是虚拟环境管理器，pip是包管理器，那么conda则是两者的结合。遗憾的是conda的包管理器做的一般，大多数时候还是使用pip安装包。pip只能安装Python的包，conda可以安装一些工具软件，即使这些软件不是基于Python开发的。conda虚拟环境是独立于操作系统解释器环境的，即无论操作系统解释器什么版本（哪怕2.7），我也可以指定虚拟环境python版本为3.6（见文章开头所说原博客），而venv是依赖主环境的。对于科学计算和大数据领域的人，conda是环境自动集成了numpy这样的主流科学计算包的，venv每个包都要自行下载。conda有图形化环境管理器，venv没有。（虽然开发人员几乎不用图形界面conda）。之前安装的anaconda3就是很强大。 有conda就是一个包管理工具和安装工具，他就是要做比pip更多的事情；在python-site-packages之外管理python 库依赖关系。 而且conda同样也像virtualenv一样创建一个虚拟环境。conda可以让你同时管理安装处理你有关python的任务和跟python无关的任务conda使用了一个新的包格式，你不能交替使用pip 和conda。因为pip不能安装和解析conda的包格式。你可以使用两个工具 但是他们是不能交互的。Anaconda是一个包含180+的科学包及其依赖项的发行版本。其包含的科学包包括：conda, numpy, scipy, ipython notebook等。conda是包及其依赖项和环境的管理工具。适用语言：Python, R, Ruby, Lua, Scala, Java, JavaScript, C/C++, FORTRAN。适用平台：Windows, macOS, Linux pip是用于安装和管理软件包的包管理器。Python 3.4及后续版本：默认安装，命令为pip3。virtualenv：用于创建一个独立的Python环境的工具。 conda结合了pip和virtualenv的功能。 https://blog.csdn.net/sinat_28442665/article/details/86292354 https://blog.csdn.net/C_tommy/article/details/86706458 3）这里我选择的则是系统环境也就是自己装的python3.7.4。Interpreter（解释器）选择的是D:\Python37\python.exe Project name 输入formatlog 对应路径D:\GoWorkPath\src\formatlog finish 4) 进入项目目录-&gt; sshscript 打开下面的test.py 遇到 from pyspark import SparkContext 有红点 直接点击安装即可。然后选择文件debug 文件即可 5) 看程序用到的包 和 程序执行文件路径 ---大致可以确定是IDEA中python SDK配置的路径有误，依次点击：File–&gt;Project Structure–&gt;Platform Settings–&gt;SDKs–&gt;Python 3.7，发现Classpath下是空的，问题找到。File-&gt;Invalidate Caches/Restart; 四 mysql相关操作 pyspark的 Mysql写入 一.需要提交spark时候，加入mysql-connect jar bin/spark-submit –master yarn-client –num-executors 5 –executor-cores 20 –executor-memory 20g –jars /usr/hdp/2.4.2.0-258/sqoop/lib/mysql-connector-java.jar /opt/spark-2.1.0-bin-hadoop2.7/dig.py 备注下，执行的python程序次序不能错。不然居然找不到mysql驱动。 二.写入的python程序如下： df.write.jdbc(url=&quot;jdbc:mysql://10.0.0.03:3306/test&quot; &quot;?user=test&amp;password=test123&quot;, mode=&quot;append&quot;, table=&quot;test&quot;, properties={&quot;driver&quot;: &apos;com.mysql.jdbc.Driver&apos;}) 备注下: 1.df是要写入的数据集，类似于R中的dataframe 2.mode是表明是否追加数据，否则创建新表 3.table指定插入的mysql表 4.url是mysql的链接参数。 bin/spark-submit --master yarn-client --num-executors 5 --executor-cores 20 --executor-memory 20g --jars /usr/hdp/2.4.2.0-258/sqoop/lib/mysql-connector-java.jar /opt/spark-2.1.0-bin-hadoop2.7/dig.py 五 阿里oss的相关操作 which pip 使用which命令查看Pip路径 Python2查看pip安装的软件包名称及版本 python2 -m pip list Python3查看pip安装的软件包及版本 python3 -m pip list pip freeze 例如查看 beautifulsoup4的安装路径 pip show beautifulsoup4 yum install python-devel pip install pycryptodome pip install oss2]]></content>
      <categories>
        <category>spark</category>
      </categories>
      <tags>
        <tag>hadoop spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php面试题一]]></title>
    <url>%2F2019%2F07%2F25%2Fphp%E9%9D%A2%E8%AF%95%E9%A2%98%E4%B8%80%2F</url>
    <content type="text"><![CDATA[1 写一个函数，获取一篇文章内容中的全部图片，并下载 $html = file_get_contents($url); preg_match_all(‘/&lt;img[^&gt;]src=”([^”])”[^&gt;]&gt;/i’,$html, $matchs); //2、什么是CSRF攻击？XSS攻击？如何防范？ 防范方式: CSRF TOKEN, 即提交表单时同时提交一段由服务端渲染表单时生成的token,通过校验token来防范csrf攻击 简单来说,XSS就是正常页面执行了用户或黑客提交的前端代码,比如你用了eval(‘这里执行了用户提交的代码’), 或者你的页面正常解析了用户提交的html代码,如用户提交的个人信息是:window.href=”恶意网站连接”, 而你不加过滤转义就入库,然后页面正常解析html代码,最终用户访问这个页面就会跳转到恶意网站 ,这就是XSS 防范方式: 过滤&amp;&amp;转义用户输入(如htmlentities、htmlspecialchars),永久不要信任客户端3 应用中我们经常会遇到在user表随机调取10条数据来展示的情况，简述你如何实现该功能。 select from user where rand() limit 10;4 MYSQL中主键与唯一索引的区别 主键是一种约束，唯一索引是一种索引，两者在本质上是不同的 主键创建后一定包含一个唯一性索引，唯一性索引并不一定就是主键 唯一性索引列允许空值，而主键列不允许为空值 主键列在创建时，已经默认为空值 + 唯一索引了 主键可以被其他表引用为外键，而唯一索引不能 一个表最多只能创建一个主键，但可以创建多个唯一索引 主键更适合那些不容易更改的唯一标识，如自动递增列、身份证号等 在 RBO 模式下，主键的执行计划优先级要高于唯一索引。 两者可以提高查询的速度5 http状态码及其含意 200 - 请求成功 301 - 资源（网页等）被永久转移到其它URL 404 - 请求的资源（网页等）不存在 500 - 内部服务器错误 300 种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择 302 临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI 400 客户端请求的语法错误，服务器无法理解 401 请求要求用户的身份认证 403 服务器理解请求客户端的请求，但是拒绝执行此请求 501 服务器不支持请求的功能，无法完成请求 502 充当网关或代理的服务器，从远端服务器接收到了一个无效的请求]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux常用命令]]></title>
    <url>%2F2019%2F07%2F25%2Flinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[1 netstat -anp 显示系统端口使用情况 lsof -i :80 显示占用80端口的进程情况 uname -a 内核信息 cat /proc/interrupts 显示中断信息 netstat -ntlp //查看当前所有tcp端口 netstat -ntulp |grep 80 //查看所有80端口使用情况 -t (tcp) 仅显示tcp相关选项 -u (udp)仅显示udp相关选项 -n 拒绝显示别名，能显示数字的全部转化为数字 -l 仅列出在Listen(监听)的服务状态 -p 显示建立相关链接的程序名 netstat -an | grep 3306 //查看所有3306端口使用情况 telnet ip 80 方式测试远程主机80是否打开 netstat -nap | grep [pid] 查看某个进程占用的端口 2 查看文件内容 cat 可以加more 、less控制输出的内容的大小 cat a.text | more chown -R www:www timeapi 修改timeapi目录为www:www 递归子目录修改： chown -R tuxapp source/ 增加脚本可执行权限： chmod a+x myscript 文本替换 sed sed [options] &apos;command&apos; file(s) 首处替换 sed &apos;s/text/replace_text/&apos; file //替换每一行的第一处匹配的text 全局替换 sed &apos;s/text/replace_text/g&apos; file 移除空白行 sed &apos;/^$/d&apos; file sed &apos;s/book/books/&apos; file #替换文本中的字符串： sed &apos;s/book/books/g&apos; file sed &apos;/^$/d&apos; file #删除空白行 sed -i “s/oldstring/newstring/g” grep oldstring -rl path 比如，要将目录/modules下面所有文件中的zhangsan都修改成lisi，这样做： sed -i “s/zhangsan/lisi/g” `grep zhangsan -rl /modules` 例子 将hexo目录下dn-lbstatics.qbox.me替换为busuanzi.ibruce.info 确保阅读次数准确 sed -i &quot;s/dn-lbstatics.qbox.me/busuanzi.ibruce.info/g&quot; `grep dn-lbstatics.qbox.me -rl hexo/` sed -i “s/6/sk/g” grep 6 -rl /home/work/test/*.sh # 注意这里的 &quot; &amp; &quot; 符号，如果没有 “&amp;”，就会直接将匹配到的字符串替换掉 sed &apos;s/^/添加的头部&amp;/g&apos; #在所有行首添加 sed &apos;s/$/&amp;添加的尾部/g&apos; #在所有行末添加 sed &apos;2s/原字符串/替换字符串/g&apos; #替换第2行 sed &apos;$s/原字符串/替换字符串/g&apos; #替换最后一行 sed &apos;2,5s/原字符串/替换字符串/g&apos; #替换2到5行 sed &apos;2,$s/原字符串/替换字符串/g&apos; #替换2到最后一行 sed &apos;s/原字符串/替换字符串/2g&apos; #替换2到最后一行 tail -n 24 可以指定显示行数 查看文件的前多少行 head -n100 filename 3 数据流处理awk #统计日志中访问最多的10个IP awk &apos;{a[$1]++}END{for(i in a)print a[i],i|&quot;sort -k1 -nr|head -n10&quot;}&apos; access.log 消除重复行 sort unsort.txt | uniq 4 统计 wc wc [-clw][–help][–version][文件…] -c或–bytes或–chars 只显示Bytes数。 -l或–lines 只显示行数。 -w或–words 只显示字数。 –help 在线帮助。 –version 显示版本信息。 wc -l fileA // 统计A文件行数 wc -w file // 统计单词数 wc -c file // 统计字符数 5 hosts文件定时备份及开机恢复 加反斜杠 \cp 执行cp命令时不走alias：（注：推荐这个方法！） vim hostsbak.sh #！/usr/bin/bash export LANG=&quot;en_US.UTF-8&quot; # \cp -rf /etc/hosts /data/server/pinedd/work/hosts.bak vim hostsload.sh #！/usr/bin/bash export LANG=&quot;en_US.UTF-8&quot; # \cp -rf /data/server/pinedd/work/hosts.bak /etc/hosts crontab 里 10 01 * * * bash /data/server/pinedd/work/script/hostsbak.sh 1&gt;/data/server/pinedd/work/script/hostsbak.log 2&gt;&amp;1 在/etc/rc.d/rc.local中加入以下语句： 开机自动执行此目录的脚本 echo &quot;su - ricky -c &apos;/bin/bash /data/server/pinedd/work/script/hostsload.sh&apos;&quot; 1&gt;/data/server/pinedd/work/script/hostsload.log 2&gt;&amp;1 6 登录远端服务器后 sz aaa.txt 下载aaa.txt到本地 rz 选择aaa.txt 上传本地aaa.txt到远端 7 screen命令 screen [-AmRvx -ls -wipe][-d &lt;作业名称&gt;][-h &lt;行数&gt;][-r &lt;作业名称&gt;][-s ][-S &lt;作业名称&gt;] -A 将所有的视窗都调整为目前终端机的大小。 -d &lt;作业名称&gt; 将指定的screen作业离线。 -h &lt;行数&gt; 指定视窗的缓冲区行数。 -m 即使目前已在作业中的screen作业，仍强制建立新的screen作业。 -r &lt;作业名称&gt; 恢复离线的screen作业。 -R 先试图恢复离线的作业。若找不到离线的作业，即建立新的screen作业。 -s 指定建立新视窗时，所要执行的shell。 -S &lt;作业名称&gt; 指定screen作业的名称。 -v 显示版本信息。 -x 恢复之前离线的screen作业。 -ls或--list 显示目前所有的screen作业。 -wipe 检查目前所有的screen作业，并删除已经无法使用的screen作业。 screen -S yourname -&gt; 新建一个叫yourname的session screen -ls -&gt; 列出当前所有的session screen -r yourname -&gt; 回到yourname这个session screen -d yourname -&gt; 远程detach某个session screen -d -r yourname -&gt; 结束当前session并回到yourname这个session Ctrl+D 最小化，后台运行 用screen -wipe命令清除该会话 Attached为当前有会话连接，Detached为会话断开 screen -X -S 374744 quit 结束某个会话 root用户下exit就可以结束某个会话 常用的 在root用户下 screen -S yourname -&gt; 新建一个叫yourname的session screen -ls -&gt; 列出当前所有的session ctrl+a 然后 d挂起某个会话 8 grep命令详解 https://www.jianshu.com/p/4ec50fdaf388 grep or 操作符 1 使用 | grep ‘pattern1|pattern2’ filename grep ‘Tech|Sales’ employee.txt 2 使用选项 -E grep -E ‘pattern1|pattern2’ filename grep -E ‘Tech|Sales’ employee.txt 3 使用 egrep egrep ‘pattern1|pattern2’ filename egrep ‘Tech|Sales’ employee.txt 4 使用选项 -e grep -e pattern1 -e pattern2 filename grep -e Tech -e Sales employee.txt grep and 操作 1 使用 -E &apos;pattern1.*pattern2&apos; grep -E &apos;pattern1.*pattern2&apos; filename grep -E &apos;pattern1.*pattern2|pattern2.*pattern1&apos; filename 两个pattern的顺序不是固定的，可以是乱序的 grep -E &apos;Manager.*Sales|Sales.*Manager&apos; employee.txt 2 使用多个grep命令 grep -E &apos;pattern1&apos; filename | grep -E &apos;pattern2&apos; grep Manager employee.txt | grep Sales grep not 操作 1 使用选项 grep -v grep -v &apos;pattern1&apos; filename 2 可以将NOT操作与其他操作联合起来，以此实现更强大的功能 组合。 egrep &apos;Manager|Developer&apos; employee.txt | grep -v Sales 9 vim命令 https://www.cnblogs.com/liu0799/p/10239791.html Esc –退出编辑模式，进入命令模式 x –命令模式下，相当于我们平时用的删除键。 Delete –命令模式下，跟我们平时用的del键是一样的 dd –删除该光标所在的行，将整行都给删除掉。 u 撤消最后一次修改 U 撤消当前行的所有修改 y0 复制光标所在行中的首字母到光标所在的字母之间的数据 (不包含光标上的字母） y$ 复制光标所在行中的光标所在字母到行尾之间的数据（包含光标上的字母） y1G 复制第1行到光标所在行的所有数据 yG 复制光标所在行到最后一行所有的数据 0 (零按键) 移动到当前行的行首。 $ 移动到当前行的末尾。 G 移动到文件末尾。 H 将光标移动到屏幕的顶行 nH 将光标移动到屏幕顶行下的第 n 行 n 在同一方向重复查找 N 在相反方向重复查找 10 awk命令 https://www.cnblogs.com/wangbaihan/p/9262296.html awk 是行处理器，优点是处理庞大文件时不会出现内存溢出或处理缓慢的问题，通常用来格式化文本信息。awk依次对每一行进行处理，然后输出。 命令形式 awk [-F|-f|-v] ‘BEGIN{} //{command1; command2} END{}’ file [-F|-f|-v] 大参数，-F指定分隔符，-f调用脚本，-v定义变量 var=value ’ ’ 引用代码块 BEGIN 初始化代码块，在对每一行进行处理之前，初始化代码，主要是引用全局变量，设置FS分隔符 // 匹配代码块，可以使字符串或正则表达式 {} 命令代码块，包含一条或多条命令 ;多条命令使用分号分隔 END 结尾代码块，对每一行进行处理后再执行的代码块，主要进行最终计算或输出 由于篇幅限制，可自行查找更详细的信息。这里awk命令的作用是从文件中每一行取出我们需要的字符串 sort 命令 sort将文件的每一行作为一个单位，相互比较，比较原则是从首字符向后，依次按ASCII码值进行比较，最后将他们按升序输出。 -b：忽略每行前面开始出的空格字符； -c：检查文件是否已经按照顺序排序； -d：排序时，处理英文字母、数字及空格字符外，忽略其他的字符； -f：排序时，将小写字母视为大写字母； -i：排序时，除了040至176之间的ASCII字符外，忽略其他的字符； -m：将几个排序号的文件进行合并； -M：将前面3个字母依照月份的缩写进行排序； -n：依照数值的大小排序； -o&lt;输出文件&gt;：将排序后的结果存入制定的文件； -r：以相反的顺序来排序； -t&lt;分隔字符&gt;：指定排序时所用的栏位分隔字符； uniq 命令 uniq 命令用于报告或忽略文件中的重复行，一般与sort命令结合使用 -c或——count：在每列旁边显示该行重复出现的次数； -d或–repeated：仅显示重复出现的行列； -f&lt;栏位&gt;或–skip-fields=&lt;栏位&gt;：忽略比较指定的栏位； -s&lt;字符位置&gt;或–skip-chars=&lt;字符位置&gt;：忽略比较指定的字符； -u或——unique：仅显示出一次的行列； -w&lt;字符位置&gt;或–check-chars=&lt;字符位置&gt;：指定要比较的字符。 &gt; 命令 &gt; 是定向输出到文件,如果文件不存在，就创建文件。如果文件存在，就将其清空 另外 &gt;&gt;是将输出内容追加到目标文件中。其他同&gt; 现有日志文件11.txt内容 需要分组统计nm的量 {&quot;ba&quot;:&quot;GIONEE&quot;,&quot;ip&quot;:&quot;111.85.164.152&quot;,&quot;m1&quot;:&quot;5232a3e61b8a6da97718c841919fbd21&quot;,&quot;mo&quot;:&quot;GIONEE GN5007&quot;,&quot;nm&quot;:&quot;SQG_TODAY_FIRST_OPEN&quot;,&quot;p&quot;:&quot;4&quot;,&quot;tm&quot;:1568559600,&quot;v&quot;:&quot;2.2.0&quot;} {&quot;ba&quot;:&quot;GIONEE&quot;,&quot;ip&quot;:&quot;106.9.163.80&quot;,&quot;m1&quot;:&quot;d181e463d4519d6ef87aa94975dfc6a2&quot;,&quot;mo&quot;:&quot;GIONEE M7&quot;,&quot;nm&quot;:&quot;SQG_TODAY_FIRST_OPEN&quot;,&quot;p&quot;:&quot;1&quot;,&quot;tm&quot;:1568559600,&quot;v&quot;:&quot;2.2.0&quot;} {&quot;ba&quot;:&quot;GIONEE&quot;,&quot;ip&quot;:&quot;113.6.185.218&quot;,&quot;m1&quot;:&quot;f73a98d4af94f14be333a30784e28a58&quot;,&quot;mo&quot;:&quot;GN5005&quot;,&quot;nm&quot;:&quot;BANGO_WAKE_UP_SQG_HELPER&quot;,&quot;p&quot;:&quot;1&quot;,&quot;tm&quot;:1568559600,&quot;v&quot;:&quot;2.2.0&quot;} {&quot;ba&quot;:&quot;GIONEE&quot;,&quot;ip&quot;:&quot;171.114.50.161&quot;,&quot;m1&quot;:&quot;5232a3e61b8a6da97718c841919fbd21&quot;,&quot;mo&quot;:&quot;GIONEE S10&quot;,&quot;nm&quot;:&quot;SQG_TODAY_FIRST_OPEN&quot;,&quot;p&quot;:&quot;1&quot;,&quot;tm&quot;:1568559600,&quot;v&quot;:&quot;2.2.0&quot;} {&quot;ba&quot;:&quot;GIONEE&quot;,&quot;ip&quot;:&quot;182.38.202.42&quot;,&quot;m1&quot;:&quot;92e697ffc4e2998d2b4a3aa6f80528c1&quot;,&quot;mo&quot;:&quot;GIONEE S10&quot;,&quot;nm&quot;:&quot;BANGO_WAKE_UP_SQG_HELPER&quot;,&quot;p&quot;:&quot;9&quot;,&quot;tm&quot;:1568559600,&quot;v&quot;:&quot;2.2.0&quot;} {&quot;ba&quot;:&quot;GIONEE&quot;,&quot;ip&quot;:&quot;221.9.36.175&quot;,&quot;m1&quot;:&quot;92e697ffc4e2998d2b4a3aa6f80528c1&quot;,&quot;mo&quot;:&quot;GIONEE S10&quot;,&quot;nm&quot;:&quot;BANGO_WAKE_UP_SQG_HELPER&quot;,&quot;p&quot;:&quot;1&quot;,&quot;tm&quot;:1568559600,&quot;v&quot;:&quot;2.2.0&quot;} {&quot;ba&quot;:&quot;GIONEE&quot;,&quot;ip&quot;:&quot;123.114.54.186&quot;,&quot;m1&quot;:&quot;43fc6f1d584e39bfd0b88b0b5af94028&quot;,&quot;mo&quot;:&quot;GIONEE S10&quot;,&quot;nm&quot;:&quot;BANGO_WAKE_UP_SQG_HELPER&quot;,&quot;p&quot;:&quot;1&quot;,&quot;tm&quot;:1568559600,&quot;v&quot;:&quot;2.2.0&quot;} 从每一行取出我们需要的字符串 cat 11.txt | awk -F &apos;(&quot;nm&quot;:&quot;|&quot;,&quot;p&quot;)&apos; &apos;{print $2}&apos; 输出 SQG_TODAY_FIRST_OPEN SQG_TODAY_FIRST_OPEN BANGO_WAKE_UP_SQG_HELPER SQG_TODAY_FIRST_OPEN BANGO_WAKE_UP_SQG_HELPER BANGO_WAKE_UP_SQG_HELPER BANGO_WAKE_UP_SQG_HELPER awk 命令中 -F 指定每一行的分隔符 在这里 ‘(txt=|&amp;client)’是分隔符，它是一个正则表达式。意义是，用’txt=’或’&amp;client’ 作为分隔符。 在这里会被分成1,2,3三个部分 第二部分我们需要。而’{print $2}’的意思是将每行得到的第二个值打印出来，$0代表获取的所有值 对行进行排序 先排序是因为去重与统计的 ‘uniq’命令只能处理相邻行 cat 11.txt | awk -F &apos;(&quot;nm&quot;:&quot;|&quot;,&quot;p&quot;)&apos; &apos;{print $2}&apos; | sort 统计数量与去重 cat 11.txt | awk -F &apos;(&quot;nm&quot;:&quot;|&quot;,&quot;p&quot;)&apos; &apos;{print $2}&apos; | sort | uniq -c uniq -c 中的-c 代表在每列旁边显示该行重复出现的次数 按重复次数排序 sort 的 -n：依照数值的大小排序；-r 按照相反顺序排列 4 BANGO_WAKE_UP_SQG_HELPER 3 SQG_TODAY_FIRST_OPEN 将结果输出到文件中 cat 11.txt | awk -F &apos;(&quot;nm&quot;:&quot;|&quot;,&quot;p&quot;)&apos; &apos;{print $2}&apos; | sort | uniq -c | sort -nr &gt; count.txt 去重统计总数 不是分组统计 输出5 cat 11.txt | awk -F &apos;(&quot;m1&quot;:&quot;|&quot;,&quot;mo&quot;)&apos; &apos;{print $2}&apos; | sort | uniq -c | wc -l 满足nm=SQG_TODAY_FIRST_OPEN 且根据m1去重 cat 11.txt | grep &apos;&quot;nm&quot;:&quot;SQG_TODAY_FIRST_OPEN&quot;&apos; | awk -F &apos;(&quot;m1&quot;:&quot;|&quot;,&quot;mo&quot;)&apos; &apos;{print $2}&apos; | sort | uniq -c | wc -l 等同如下jq写法 cat 11.txt | grep &apos;&quot;nm&quot;:&quot;SQG_TODAY_FIRST_OPEN&quot;&apos; | jq -r .m1 | sort | uniq -c | wc -l ##找出nm=EVENT_PASTE_SEARCH_PV 且appid=10004的pv量 cat * | grep EVENT_PASTE_SEARCH_PV | jq .seg.custom.appid | grep 10004 | wc -l ##找出nm=EVENT_PASTE_SEARCH_PV 且appid=10004的uv量,根据m1去重 cat * | grep EVENT_PASTE_SEARCH_PV | grep &apos;&quot;appid&quot;:10004&apos; | jq .m1 | sort | uniq -c | wc -l 第二种方法 先逗号分割，得到的结果 再：分割 cat * | awk -F , &apos;{print $5}&apos; | awk -F : &apos;{print $2}&apos; | sort | uniq -c | sort -nr 第三种方法jq cat 1.txt | jq .nm | sort | uniq -c 直接jq取.nm的值 cat * | jq -r &apos;.nm&apos; | grep BANGO_WAKE_UP_SQG_HELPER |wc -l //统计nm为BANGO_WAKE_UP_SQG_HELPER的个数 cat * | jq -r -c &apos;. | {nm:.nm,p:.p}&apos; | grep SQG_TODAY_FIRST_OPEN | grep &apos;&quot;p&quot;:&quot;2&quot;&apos; //满足nm=SQG_TODAY_FIRST_OPEN且p=2的 cat * | jq -r -c &apos;. | {nm:.nm,p:.p}&apos; | sort | uniq -c | sort -nr cat * | awk -F &apos;(&quot;nm&quot;:&quot;|&quot;,&quot;p&quot;)&apos; &apos;{print $2}&apos; | sort | uniq -d -d或--repeated 仅显示重复出现的行 -u或--unique 仅显示出现一次的行 单条日志如下： {&quot;ba&quot;:&quot;GIONEE&quot;,&quot;ip&quot;:&quot;112.98.134.22&quot;,&quot;m1&quot;:&quot;0d8578b9e18eeffe0af469f4dbbb5e9b&quot;,&quot;mo&quot;:&quot;GIONEES10C&quot;,&quot;nm&quot;:&quot;AUTO_UPLOAD_USE_TIME_LIST_DATA&quot;,&quot;p&quot;:&quot;1&quot;,&quot;seg&quot;:{&quot;custom&quot;:{&quot;appv&quot;:&quot;3.5.1&quot;,&quot;data&quot;:[&quot;ALIVE_MYSELF@@3@@1570541425477&quot;,&quot;OPEN@@2@@1570549769170&quot;,&quot;OPEN@@2@@1570549869956&quot;,&quot;OPEN@@2@@1570549945797&quot;,&quot;OPEN@@4@@1570549989446&quot;,&quot;OPEN@@2@@1570550009438&quot;,&quot;OPEN@@6@@1570550108061&quot;,&quot;OPEN@@2@@1570550171468&quot;,&quot;OPEN@@2@@1570550250246&quot;,&quot;OPEN@@2@@1570550323524&quot;,&quot;OPEN@@4@@1570550365150&quot;,&quot;OPEN@@2@@1570550404568&quot;,&quot;OPEN@@2@@1570550461831&quot;,&quot;OPEN@@2@@1570550516939&quot;,&quot;OPEN@@7@@1570550614604&quot;],&quot;from&quot;:&quot;gionee&quot;}},&quot;tm&quot;:1570550624,&quot;v&quot;:&quot;2.2.0&quot;} 一：统计活跃PV的旧版拉活的出现OPEN@@的日志条数 cat * | grep AUTO_UPLOAD_USE_TIME_LIST_DATA | grep OPEN@@ | wc -l 二：活跃PV的旧版拉活的出现OPEN@@的次数，一条日志里出现多次。用OPEN@@分割得出每条日志出现的次数，然后累加 cat * | grep AUTO_UPLOAD_USE_TIME_LIST_DATA | grep OPEN@@ | awk -FOPEN@@ &apos;{print NF-1}&apos; | awk &apos;{sum+=$1} END {print sum}&apos; NF 表示的是浏览记录的域的个数 $NF 表示的最后一个Field（列），即输出最后一个字段的内容 NF其实是number of field, 即整行(或者说record)里面词 (更准确的翻译应该是域)的总数 $(NF-1) 就是倒数第二个词 扩展 grep &apos;17:[0-9][0-9]:&apos; awk.sh | awk -F, &apos;{if(int($19)&gt;=0)print $10}&apos; | sort | uniq -c | sort -n 这句-F, 表示根据逗号分割 分割后第19行大于0 -n表示正序排列 cat * | awk -F &apos;(&quot;p&quot;:&quot;|&quot;,&quot;tm&quot;)&apos; &apos;{sum += $2} END {print sum}&apos; 统计p的和 11 jq命令 https://www.jianshu.com/p/3522fe70de19 https://www.linuxidc.com/Linux/2017-10/148037.htm https://www.jianshu.com/p/851015d1b186 安装EPEL源： yum install epel-release 安装 yum install jq yum install -y jq cat * | jq &apos;. | {nm:.JINGANG_CLICK_EVERYTIME,name:.淘宝白菜}&apos; | wc -l cat * | jq &apos;.[0] | {nm:.name,city:.address.city}&apos; jq支持使用map()或者map_values()遍历列表，或者对象的值。 例如 echo &apos;{&quot;a&quot;:1,&quot;b&quot;:2,&quot;c&quot;:3}&apos; | jq &apos;map_values(1 + .)&apos; echo &apos;[1,2,3]&apos; | jq &apos;map(1 + .)&apos; 删除某个key jq &apos;del(filter)&apos; json.data key 是用来获取JSON中的 key 元素的： cat json_raw.txt | jq &apos;keys&apos; 检查某个key是否存在 cat json_raw.txt | jq &apos;has(&quot;name&quot;)&apos; 合并 jq -n &apos;{a:&quot;test&quot;} + {b:2}&apos; 删除 cat test.json |jq &apos;del(.b)&apos; 更新 cat test.json |jq &apos;.b=&quot;testb&quot;&apos; 查询 cat test.json |jq &apos;. + {d:4}&apos; |jq &apos;.d={dd:5}&apos; |jq .d.dd //{ &quot;a&quot;: &quot;test&quot;, &quot;b&quot;: 2, &quot;c&quot;: &quot;testc&quot;, &quot;d&quot;: { &quot;dd&quot;: 5 } } 查看数据类型 echo &quot;{}&quot; |jq -r type echo &apos;[0, false, [], {}, null, &quot;hello&quot;]&apos; |jq &apos;map(type)&apos; 查询数组中的值 echo [1,2,3] |jq .[1] 查询数组长度 echo [1,2,3,9] |jq &apos;.|length&apos; 数组相加 echo [1,2,3] |jq &apos;. + [4,5,6]&apos; 高级查询 echo [1,2,3] | jq &apos;map(select(. &gt;= 2))&apos; echo [1,2,3] | jq &apos;map(select(. != 2))&apos; 类型转换 echo &apos;[&quot;a&quot;,&quot;b,c,d&quot;,&quot;e&quot;]&apos; |jq &apos;join(&quot;,&quot;)&apos; jq -R &apos;split(&quot;,&quot;)|{&quot;name&quot;:.[0],&quot;age&quot;:.[1],&quot;sex&quot;:.[2]}&apos; ./test.json 计算元素长度，对于对象，length表示对象里的元素个数，对于string，length表示string字符数，对于列表，表示列表元素个数 jq &apos;.age | length&apos; 1.txt sort -t &apos;,&apos; -k 1,1 -u 其中 -t 指定列之间的分隔符， -k 指定从第几列到第几列作为去重标准 -c或--count 在每列旁边显示该行重复出现的次数 -d或--repeated 仅显示重复出现的行 -f&lt;栏位&gt;或--skip-fields=&lt;栏位&gt; 比较时跳过前n列，从n+1列开始比较 -s&lt;字符位置&gt;或--skip-chars=&lt;字符位置&gt;比较时跳过前n个字符，从n+1个字符开始比较 -u或--unique 仅显示出现一次的行 -w&lt;字符位置&gt;或--check-chars=&lt;字符位置&gt;对每行第n个字符以后的内容不作对照 最简单的jq程序是表达式&quot;.&quot;，它不改变输入，但可以将其优美地输出，便于阅读和理解。cat json.txt | jq &apos;.&apos; 输出列表中的第一个元素，可以使用[index]： cat json.txt | jq &apos;.[0]&apos; curl -X http://localhost:8080/a/b | jq . Some of the options include: -c compact instead of pretty-printed output; -n use `null` as the single input value; -e set the exit status code based on the output; -s read (slurp) all inputs into an array; apply filter to it; -r output raw strings, not JSON texts; -R read raw strings, not JSON texts; //输出SQG_TODAY_FIRST_OPEN 没有双引号 -C colorize JSON; -M monochrome (don&apos;t colorize JSON); -S sort keys of objects on output; --tab use tabs for indentation; --arg a v set variable $a to value &lt;v&gt;; --argjson a v set variable $a to JSON value &lt;v&gt;; --slurpfile a f set variable $a to an array of JSON texts read from &lt;f&gt;;]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php常用命令]]></title>
    <url>%2F2019%2F07%2F25%2Fphp%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[1、PHP运行指定文件 php -f test.php (-f 可省略) 2、命令行直接运行PHP代码 php -r “phpinfo();” 如果结果太长，还可以 php -r “phpinfo();” | less 分页展示 3、交互模式运行PHP php -a php &gt; echo (2+3); 5 control + c/z 或者 exit 退出交互模式 4、PHP脚本作为shell脚本运行 没有权限则切换到root用户 sudo su echo ‘#!/usr/bin/php\n&lt;?php var_dump($argv); ?&gt;’ &gt; phpscript #累计数据快照 1 0 * * * flock -xn /home/rong/crontab/UnderRepaymentTimeoutdone.lock -c &apos;/usr/bin/php /home/rong/www/time-order/webroot/command.php HistorySnapshot InsertHistoryData&apos; 5、其他常用命令 php -m 内置及Zend加载的模块 php -i 等价于 phpinfo() php -i | grep php.ini 查看php配置文件加载路径 php –ini 同上 php -v 查看php版本 php –version 同上 php –re 查看是否安装相应的扩展 如 php –re gd 6 php -S 这个内置的Web服务器主要用于本地开发使用，不可用于线上产品环境。 如果请求未指定执行哪个PHP文件，则默认执行目录内的index.php 或者 index.html。如果这两个文件都不存在，服务器会返回404错误。 当你在命令行启动这个Web Server时，如果指定了一个PHP文件，则这个文件会作为一个“路由”脚本，意味着每次请求都会先执行这个脚本。如果这个脚本返回 FALSE ，那么直接返回请求的文件（例如请求静态文件不作任何处理）。否则会把输出返回到浏览器。 php -S localhost:8000 服务于当前目录 php -S localhost:8000 -t foo/ 启动时指定根目录 php -S localhost:8000 router.php 使用路由（Router）脚本]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[devops-api notes]]></title>
    <url>%2F2019%2F07%2F22%2Fdevops-api-notes%2F</url>
    <content type="text"><![CDATA[token 暂不需要 关了 magicpush init //生成token //配置token magicpush token –create=xiaoayong –root-token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoicm9vdCIsInVwZGF0ZVRpbWUiOjE1MzA5NDIzNzJ9.-NUb3vqQQYs_83TliNDlXqHcuMlEWP8FDBj2GdDZgyE nohup magicpush server --mode=dev &amp; ##linux 请求头 MAGICPUSH-TOKEN 加上生成的 eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoieGlhb2F5b25nIiwidXBkYXRlVGltZSI6MTUzMDk0MjQ0Nn0.KS1CrMPC5A4sKTMC1AcPoF-soSUmELa8FE5dgZAv1GY 一：http://127.0.0.1:7070/api/v1/sendmsg/dingding post 不要添加请求头 form-data发送一下内容 POST /api/v1/sendmsg/dingding msgType： text|markdown msg: 要发送的消息 title: 发送markdown消息时需要指定此参数，指定标题 url: 可以指定钉钉机器人的URL，这样就不用在conf/app.conf 配置钉钉机器人的URL 注意: 在发送markdown消息时，markdown的语法可以查看官方文档 二 http://127.0.0.1:7070/api/v1/sendmsg/weixin post form-data msgType text 消息类型,目前只支持文本消息 toTag 1 toUser XiaoAYong toParty 3 msg aa 我的脚本执行状况\n[脚本描述：测试]\n[脚本描述：测试]\n[脚本执行时间：20180629]\n 三 设置节假日和工作日 POST /api/v1/holiworkday 2018年 { “year”: “2018”, “holiday”: [ { “name”: “yuandan”, “zh_name”: “元旦”, “start_time”: “2018-01-01”, “end_time”: “2018-01-01” }, { “name”: “chunjie”, “zh_name”: “春节”, “start_time”: “2018-02-15”, “end_time”: “2018-02-21” }, { “name”: “qingming”, “zh_name”: “清明节”, “start_time”: “2018-04-05”, “end_time”: “2018-04-07” }, { “name”: “laodong”, “zh_name”: “劳动节”, “start_time”: “2018-04-29”, “end_time”: “2018-05-01” }, { “name”: “duanwu”, “zh_name”: “端午节”, “start_time”: “2018-06-16”, “end_time”: “2018-06-18” }, { “name”: “zhongqiu”, “zh_name”: “中秋节”, “start_time”: “2018-09-22”, “end_time”: “2018-09-24” }, { “name”: “guoqing”, “zh_name”: “国庆节”, “start_time”: “2018-10-01”, “end_time”: “2018-10-07” } ], “workday”: [ “2018-02-11”, “2018-02-24”, “2018-04-08”, “2018-04-28”, “2018-09-29”, “2018-09-30” ] } 2019年 { “year”: “2019”, “holiday”: [ { “name”: “yuandan”, “zh_name”: “元旦”, “start_time”: “2019-01-01”, “end_time”: “2019-01-01” }, { “name”: “chunjie”, “zh_name”: “春节”, “start_time”: “2019-02-04”, “end_time”: “2019-02-10” }, { “name”: “qingming”, “zh_name”: “清明节”, “start_time”: “2019-04-05”, “end_time”: “2019-04-07” }, { “name”: “laodong”, “zh_name”: “劳动节”, “start_time”: “2019-05-01”, “end_time”: “2019-05-04” }, { “name”: “duanwu”, “zh_name”: “端午节”, “start_time”: “2019-06-07”, “end_time”: “2019-06-09” }, { “name”: “zhongqiu”, “zh_name”: “中秋节”, “start_time”: “2019-09-13”, “end_time”: “2019-09-15” }, { “name”: “guoqing”, “zh_name”: “国庆节”, “start_time”: “2019-10-01”, “end_time”: “2019-10-07” } ], “workday”: [ “2018-02-02”, “2018-02-03”, “2018-04-28”, “2018-05-05”, “2018-09-29”, “2018-10-12” ] } 四 判断给定的日期是节假日工作日周末 GET /api/v1/holiworkday?date=2018-08-25 五 IP地址查询 GET /api/v1/queryip?ip=xxx.xxx.xxx.xxx http://127.0.0.1:7070/api/v1/queryip?ip=47.75.129.108 六 GET /api/v1/queryphone?phone=手机号 http://127.0.0.1:7070/api/v1/queryphone?phone=18612309765 七 windows操作指南 SET CGO_ENABLED=0 SET GOOS=windows go build -o devops-win-amd64.exe main.go start /b devops-win-amd64.exe server –mode=dev 八 方糖server 原始请求 https://sc.ftqq.com/$key.send?text=order_attachment脚本错误&amp;desp=正式服务器 http://127.0.0.1:7070/api/v1/weixin?text=order_attachment脚本错误&amp;desp=正式服务器]]></content>
  </entry>
  <entry>
    <title><![CDATA[talang work notes]]></title>
    <url>%2F2019%2F07%2F22%2Ftalang-work-notes%2F</url>
    <content type="text"><![CDATA[talang–notes sz DashboardController.php 保存服务器文件到本地 php -f encrypt.php &gt;test.txt 再redis-cli SADD time_user_whitelist 84 假如白名单 SISMEMBER time_user_whitelist 333 //判断uid333在不在白名单 SCARD time_user_whitelist //获取集合个数 SMEMBERS key //获取集合所有成员 Ctrl + H 输入^，然后Find All，查找所有的行首 输入$，然后Find All，查找所有的行尾 const NEW_ORDER = 10;//新订单 const AUDIT_LOADING = 40;//审批中 const AUDIT_SUCCESS = 60;//审批成功 const AUDIT_REFUSED = 50;//审批拒绝 const BLACK_REFUSED = 30;//欺诈拒绝 const WAIT_INVESTOR = 75;//待资金方确认 const LENDING_LOADING = 80;//放款处理中 const AGAIN_LENDING = 85;//待重新放款 const LENDING_SUCCESS = 90;//放款成功 const LENDING_FAILED = 100;//放款失败 const ROLLOVER_DEAL = 115;//展期处理中 const PREREPAY_LOADING = 130;//提前还款处理中 const NORMAL_LOADING = 110;//正常还款中 const LOAN_CANCEL = 70;//贷款取消 const PRE_SETTLE = 150;//提前结清 const NORMAL_SETTLE = 140;//正常结清 const OVERDUE_SETTLE = 160;//逾期结清 const OVERDUE = 120;//已逾期 ***core.repayment_plan表里status的值 有 1 2 3 4 5 6 这些状态********** select id,`status` FROM core.repayment_plan where 1=1 GROUP BY `status`; 状态：1 新建，2 成功，3 失败，4 由于提前还款账单取消 5 已申请提前还款 6 还款处理中 7 因提前还款失败而废弃 8 展期处理中 9 展期成功 10 因展期成功而废弃 ***core.repayment_plan表里overdue_status的值 有 0 1 这些状态********** select id,`overdue_status` FROM core.repayment_plan where 1=1 GROUP BY `overdue_status`; 还款计划是否有过逾期 0-未逾过期 1-逾过期 ***core.repayment_fees表里type的值 有 1 2 3 这些状态********** select id,`type` FROM core.repayment_fees where 1=1 GROUP BY `type`; 还款类型，1 一次性服务费,2 正常还款,3 提前还款 ***core.repayment_fees表里fee_type的值 有 1 2 3 4 这些状态********** select id,`fee_type` FROM core.repayment_fees where 1=1 GROUP BY `fee_type`; 还款的费用类型，1 本金,2 利息, 3 一次性服务费, 4 逾期利息 5//展期服务费 ***core.repayment_fees表里status的值 有 1 2 3 4 5 6 这些状态********** select id,`status` FROM core.repayment_fees where 1=1 GROUP BY `status`; 费用状态，已经结清，部分结清，未结清 ???????? 同 状态：1 新建，2 成功，3 失败，4 由于提前还款账单取消 5 已申请提前还款 6 还款处理中 7 因提前还款失败而废弃 8 展期处理中 9 展期成功 10 因展期成功而废弃]]></content>
  </entry>
  <entry>
    <title><![CDATA[hexo笔记]]></title>
    <url>%2F2019%2F07%2F22%2Fhexo%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[hexo安装及常用方式安装及常用命令 npm install -g hexo hexo g ## 生成 hexo s ## 启动服务 打开浏览器访问 http://localhost:4000 即可看到内容 首先，ssh key肯定要配置好。 其次，配置_config.yml中有关deploy的部分： deploy: type: git repository: git@github.com:xay216216/xay216216.github.io.git branch: master hexo s -g #生成并本地预览 hexo d -g #生成并上传 日常hexo操作 在E:\phpStudy\PHPTutorial\WWW\hexo 打开git bash hexo n ‘hexo笔记’ 然后 E:\phpStudy\PHPTutorial\WWW\hexo\source_posts\hexo笔记.md 修改文件 然后保存 hexo s ##启动服务 关掉服务 hexo d -g #生成并上传 友情链接 https://www.jianshu.com/p/3a05351a37dc]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sudo的用法]]></title>
    <url>%2F2019%2F03%2F15%2Fsudo%E7%9A%84%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[深度linux和ubuntu apt-cache search # ——(package 搜索包) apt-cache show #——(package 获取包的相关信息，如说明、大小、版本等) sudo apt-get install # ——(package 安装包)sudo apt-get install # —–(package - - reinstall 重新安装包) sudo apt-get -f install # —–(强制安装?#”-f = –fix-missing”当是修复安装吧…) sudo apt-get remove #—–(package 删除包) sudo apt-get remove - - purge # ——(package 删除包，包括删除配置文件等) sudo apt-get autoremove –purge # —-(package 删除包及其依赖的软件包+配置文件等（只对6.10有效，强烈推荐）) sudo apt-get update #——更新源 sudo apt-get upgrade #——更新已安装的包 sudo apt-get dist-upgrade # ———升级系统 sudo apt-get dselect-upgrade #——使用 dselect 升级 apt-cache depends #——-(package 了解使用依赖) apt-cache rdepends # ——(package 了解某个具体的依赖?#当是查看该包被哪些包依赖吧…) sudo apt-get build-dep # ——(package 安装相关的编译环境) apt-get source #——(package 下载该包的源代码) sudo apt-get clean &amp;&amp; sudo apt-get autoclean # ——–清理下载文件的存档 &amp;&amp; 只清理过时的包 sudo apt-get check #——-检查是否有损坏的依赖 apt-get install apt-get remove的用法 apt-get remove [–purge] apt-get update apt-cache search的用法 apt-cache search apt-cache show 的用法 apt-cache show apt-cache showpkg 的用法 apt-cache showpkg sudo systemctl start php-fpm sudo systemctl start nginx sudo systemctl enable php-fpm sudo systemctl enable nginx 重启SSH服务，命令：systemctl restart sshd.service centos 7 linux命令 systemctl start mysqld.service 启动mysql服务 systemctl status mysqld.service 查看服务状态 mysql -uroot -p 链接mysql yum list installed | grep php 列出phpan安装的信息 yum remove php70w.x86_64 下载 rpm -qa | grep mysql 查看MySQL安装信息 centos安装PHP7.0 PHP-fpm nginx http://os.51cto.com/art/201703/534277.htm yum -y install epel-release yum -y install nginx rpm -Uvh https://mirror.webtatic.com/yum/el7/webtatic-release.rpm yum -y install php70w-fpm php70w-cli php70w-gd php70w-mcrypt php70w-mysql php70w-pear php70w-xml php70w-mbstring php70w-pdo php70w-json php70w-pecl-apcu php70w-pecl-apcu-devel]]></content>
      <tags>
        <tag>sudo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git使用命令]]></title>
    <url>%2F2019%2F03%2F15%2Fgit%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[常用git命令 git clone ** 建仓库 cd 到仓库 git status 查看当前状态 git pull origin master （加入本地现在是master分支） git checkout -b KF-660 基于master分支建一个本地KF-660 git设置alias [alias] st = status co = checkout ci = commit br = branch rt = remote last = log -1 –name-status al = log –pretty=format:’%h %cn -%d %s (%cd)’ –abbrev-commit -30 l = log –graph –pretty=format:’%Cred%h%Creset %Cgreen%cn -%C(cyan)%d%Creset %s %Cgreen(%cd)%Creset’ –abbrev-commit -30 ll = log –name-status –graph –pretty=format:’%Cred%h%Creset %Cgreen%cn -%C(cyan)%d%Creset %s %Cgreen(%cd)%Creset’ –abbrev-commit -10 现在让我们来重置回第一次提交的状态： git status git checkout 文件名 取消修改某文件 git log git reset –hard b7057a9 本地回滚到上次的某个版本号 git status 回滚后,再次查看当前本地分支状态 git add . git commit -m ‘增加’ 提交 git pull origin KF-660 拉去远端最新的KF-660 git push origin KF-660 推到远端KF-660分支 git checkout develop git pull origin develop 拉去最新的develop分支 git merge KF-660 develop分支合KF-660的代码 git push origin develop 推到远端的develop分支推到正式 git checkout master git pull origin master git merge KF-660 git push origin master git tag v1.1.5.35 打一个tag号 git push origin v1.1.5.35 查找问题–查看文件改动 git blame -L 183,+100 app/controllers/web/NewsController.php 查看某个文件第183行的改动记录，取100行记录 git log –pretty=oneline app/controllers/web/NewsController.php 文件的所有的改动历史 查看、添加、提交、删除、找回，重置修改文件 git help # 显示command的help git show # 显示某次提交的内容 git show $id git co – # 抛弃工作区修改 git co . # 抛弃工作区修改 git add # 将工作文件修改提交到本地暂存区 git add . # 将所有修改过的工作文件提交暂存区 git rm # 从版本库中删除文件 git rm –cached # 从版本库中删除文件，但不删除文件 git reset # 从暂存区恢复到工作文件 git reset – . # 从暂存区恢复到工作文件 git reset –hard # 恢复最近一次提交过的状态，即放弃上次提交后的所有本次修改 git ci git ci . git ci -a # 将git add, git rm和git ci等操作都合并在一起做 git ci -am “some comments” git ci –amend # 修改最后一次提交记录 git revert &lt;$id&gt; # 恢复某次提交的状态，恢复动作本身也创建次提交对象 git revert HEAD # 恢复最后一次提交的状态 查看文件diff git diff # 比较当前文件和暂存区文件差异 git diff git diff # 比较两次提交之间的差异 git diff .. # 在两个分支之间比较 git diff –staged # 比较暂存区和版本库差异 git diff –cached # 比较暂存区和版本库差异 git diff –stat # 仅仅比较统计信息 查看提交记录 git log git log # 查看该文件每次提交记录 git log -p # 查看每次详细修改内容的diff git log -p -2 # 查看最近两次详细修改内容的diff git log –stat #查看提交统计信息 一般配置 git –version //查看git的版本信息 git config –global user.name //获取当前登录的用户 git config –global user.email //获取当前登录用户的邮箱 git config –global user.name ‘userName’ //设置git账户，userName为你的git账号， git config –global user.email ‘email’ 友情链接 https://sinchie.com/posts/git-remark/比较的是历史区和工作区的差异（修改） git diff master撤回内容(如果修改了工作区的文件后发现改错了，可以用暂存区或者版本库里的文件替换掉工作区的文件)用暂存区中的内容或者版本库中的内容覆盖掉工作区 git checkout index.html取消增加到暂存区的内容（添加时） git reset HEAD index.html//显示目录的状体 有没有添加或者修改文件 git status]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[welcome to kobe's blog]]></title>
    <url>%2F2018%2F09%2F06%2Fwelcome-to-my-blog%2F</url>
    <content type="text"><![CDATA[阿飘莱勇飞趣–认真创造，安静面对，乐观变化，幸福时间，美。]]></content>
  </entry>
</search>
